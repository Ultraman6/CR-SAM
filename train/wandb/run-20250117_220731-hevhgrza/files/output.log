2025-01-17 22:07:33,531 | Epoch: [0 | 200]
2025-01-17 22:07:49,723 | Phase:train -- Batch_idx:100/391-- 790.51 samples/sec-- Loss:2.73 -- Acc:10.32
2025-01-17 22:08:00,277 | Phase:train -- Batch_idx:200/391-- 957.13 samples/sec-- Loss:2.43 -- Acc:14.32
2025-01-17 22:08:10,545 | Phase:train -- Batch_idx:300/391-- 1037.45 samples/sec-- Loss:2.29 -- Acc:16.87
Train Loss : 2.206323840560913, Train Accuracy : 18.686 , round:  0
Test Loss : 1.6940755588531493, Test Accuracy : 35.94 , round:  0
2025-01-17 22:08:22,153 | best acc:35.94
2025-01-17 22:08:22,230 | Epoch: [1 | 200]
wandb: WARNING Tried to log to step 0 that is less than the current step 390. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 0 that is less than the current step 390. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-01-17 22:08:32,415 | Phase:train -- Batch_idx:100/391-- 1256.90 samples/sec-- Loss:1.84 -- Acc:29.45
2025-01-17 22:08:43,074 | Phase:train -- Batch_idx:200/391-- 1228.19 samples/sec-- Loss:1.81 -- Acc:30.27
2025-01-17 22:08:57,061 | Phase:train -- Batch_idx:300/391-- 1102.50 samples/sec-- Loss:1.80 -- Acc:31.30
Train Loss : 1.7734713750457765, Train Accuracy : 32.402 , round:  1
Test Loss : 1.5133061069488525, Test Accuracy : 43.0 , round:  1
2025-01-17 22:09:08,272 | best acc:43.0
2025-01-17 22:09:08,272 | Epoch: [2 | 200]
wandb: WARNING Tried to log to step 1 that is less than the current step 781. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 1 that is less than the current step 781. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-01-17 22:09:18,494 | Phase:train -- Batch_idx:100/391-- 1252.32 samples/sec-- Loss:1.66 -- Acc:37.95
2025-01-17 22:09:28,656 | Phase:train -- Batch_idx:200/391-- 1255.94 samples/sec-- Loss:1.63 -- Acc:39.02
2025-01-17 22:09:38,961 | Phase:train -- Batch_idx:300/391-- 1251.27 samples/sec-- Loss:1.61 -- Acc:39.98
Traceback (most recent call last):
  File "E:\Github\CR-SAM\train\sam_train.py", line 267, in <module>
    main(args)
  File "E:\Github\CR-SAM\train\sam_train.py", line 225, in main
    trainloss, trainacc = run_one_epoch('train', dataset.train, model, criterion, optimizer, args)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Github\CR-SAM\train\sam_train.py", line 129, in run_one_epoch
    h_f_product_p = torch.dot(grad_h_f, grad_p).item()
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
